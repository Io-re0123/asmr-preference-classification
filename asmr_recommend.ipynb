{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install pydub\n","!pip install torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8812,"status":"ok","timestamp":1710163694915,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"qm7Q8BsRODh5","outputId":"8d5ed80f-1268-4d4c-a2f6-7576a04c59c1"},"outputs":[],"source":["import shutil\n","import glob\n","import re\n","import os\n","from natsort import natsorted\n","from pydub import AudioSegment\n","from pydub.silence import split_on_silence\n","import librosa\n","import librosa.display\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchinfo import summary\n","from torchvision.models import resnet34"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2685568,"status":"ok","timestamp":1710166400667,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"Vy7afgDj9DjI","outputId":"7c716d78-0aeb-42a6-ae29-c323da6105a2"},"outputs":[],"source":["#フォルダ作成\n","for i in range(2):\n","  binary_path = f\"./{i}_asmr/\"\n","  if not os.path.exists(binary_path):\n","    os.mkdir(binary_path)\n","\n","#mp3をwavに変換\n","for path in natsorted(glob.glob(\"./asmr_trial/**/*.mp3\", recursive=True)):\n","  title = os.path.splitext(path)[0]\n","  audio = AudioSegment.from_file(path, format=\"mp3\")\n","  audio.export(f\"{title}.wav\", format=\"wav\")\n","  os.remove(path)\n","  print(title)\n","\n","#ラベリング\n","for path in natsorted(glob.glob(\"./asmr_trial/**/*.wav\", recursive=True)):\n","  title = os.path.abspath(path)\n","  title =  title.replace(\"./asmr_trial/\", \"\").replace(\"DLsite 同人 - R18\", \"\")\n","  title = re.sub(r\"/\", \"\", title)\n","\n","  #Colabの接続が途中で切れた時用\n","  #if int(title[:3]) < 6:\n","    #continue\n","  \n","  #ラベル付け\n","  label = input(f\"{title}のラベルは？\")\n","\n","  #File name too long 対策\n","  if len(title) > 76:\n","    num = title[:4]\n","    title = title[len(title) - 76:]\n","    title = num + title\n","  #print(title)\n","  \n","  if label == str(1):\n","    shutil.copy(path, f\"./1_asmr/{title}\")\n","  elif label == \"skip\":\n","    continue\n","  else:\n","    shutil.copy(path, f\"./0_asmr/{title}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5315012,"status":"ok","timestamp":1710171780624,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"jAglsRrz6pHe","outputId":"f5bd3a2d-68f8-4dee-8283-de887f7fc05d"},"outputs":[],"source":["#フォルダ内音声の無音区間カット\n","\n","for i in range(2):\n","\n","  revised_path = f\"./{i}_asmr_revised/\"\n","  if not os.path.exists(revised_path):\n","    os.mkdir(revised_path)\n","\n","  #フォルダ内のwavデータを取得\n","  for path in natsorted(glob.glob(f\"./{i}_asmr/**/*.wav\", recursive=True)):\n","\n","      # 音声ファイルを読み込む\n","      audio = AudioSegment.from_file(path)\n","      org_ms = len(audio)\n","      title = os.path.splitext(os.path.basename(path))[0]\n","      print(\"{}: {:.2f} [min]\".format(title, org_ms/60/1000))\n","\n","      #音声が27秒未満なら次の音声データへ\n","      if org_ms < 27000:\n","        print(\"skip\")\n","        continue\n","\n","      # 無音部分で分割する\n","      chunks = split_on_silence(audio, min_silence_len=200, silence_thresh=-50, keep_silence=100)\n","\n","      #無音部分が検出されなかったらスキップ\n","      if not chunks:\n","        print(\"skip\")\n","        continue\n","\n","      # 分割結果を合算して無音部分を除去した音声を作成\n","      revised_audio = sum(chunks)\n","\n","      # 無音部分を除去した音声の長さをミリ秒単位で計算\n","      revised_ms = len(revised_audio)\n","      print(\"{}_revised = {:.2f} [min]\".format(title, revised_ms/60/1000))\n","      revised_audio.export(f\"{revised_path}/{title}.wav\", format=\"wav\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151460,"status":"ok","timestamp":1710172049793,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"K8zwOfTq6Obg","outputId":"c1c43ac4-9424-4fd4-c79d-d77c32fee7c8"},"outputs":[],"source":["#音声を27秒分割→3秒ずつ分割\n","#最初の27秒を抽出\n","\n","for i in range(2):\n","  path_27 = f\"./{i}_asmr27sec/\"\n","\n","  if not os.path.exists(path_27):\n","    os.mkdir(path_27)\n","\n","  #フォルダ内のwavデータを取得\n","  for path in natsorted(glob.glob(f'./{i}_asmr_cutted/**/*.wav', recursive=True)):\n","\n","      # 音声ファイルを読み込む\n","      audio = AudioSegment.from_file(path)\n","      org_ms = len(audio)\n","      title = os.path.splitext(os.path.basename(path))[0]\n","\n","      #音声が27秒未満なら次の音声データへ\n","      if org_ms < 27000:\n","        print(\"skip\")\n","        continue\n","\n","      if not os.path.exists(path_27):\n","        os.mkdir(path_27)\n","\n","      #初めの27秒抽出\n","      sample_length = 27000\n","      if org_ms > sample_length:\n","            # ～27000ms(27秒)を抽出\n","            sound_splitted = audio[:sample_length]\n","            # 抽出した部分を出力\n","            sound_splitted.export(f\"{path_27}/{title}\", format=\"wav\")\n","\n","  path_3 = f\"./{i}_asmr3sec/\"\n","  if not os.path.exists(path_3):\n","    os.mkdir(path_3)\n","\n","  #フォルダ内のwavデータを取得\n","  for path in natsorted(glob.glob(f'./{i}_asmr27sec/**/*.wav', recursive=True)):\n","\n","      # 音声ファイルを読み込む\n","      audio = AudioSegment.from_file(path)\n","      org_ms = len(audio)\n","      title = os.path.splitext(os.path.basename(path))[0]\n","\n","      sample_length = 3000\n","      move_point = 0\n","      j = 1\n","      while org_ms > move_point:\n","            # ～3000ms(3秒)を抽出\n","            sound_splitted = audio[move_point:move_point + sample_length]\n","            move_point += 3000\n","            # 抽出した部分を出力\n","            sound_splitted.export(f\"./{i}_asmr3sec/{title}_{j}.wav\", format=\"wav\")\n","            j += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWpg1CG25rIN"},"outputs":[],"source":["#メルスペクトログラムの取得\n","# loadメソッドでy=音声信号の値（audio time series）、sr=サンプリング周波数（sampling rate）を取得\n","\n","def calc_melsp(file, n_fft=2048,  hop_length=512, n_mels=128):\n","    \n","    #音源ファイルの読み込みと波形の表示\n","    y, sr = librosa.load(file, sr=44100)\n","\n","    #メルスペクトログラム（人間の聴覚に適したスペクトログラム）\n","    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n","    melsp = librosa.power_to_db(S, ref=np.max)\n","    return melsp\n","\n","#メルスペクトログラムのnpyファイルを作成\n","for i in range(2):\n","    \n","    number = 1\n","    path_dataset = f\"./{i}_dataset\"\n","    \n","    if not os.path.exists(path_dataset):\n","      os.mkdir(path_dataset)\n","    \n","    for path in natsorted(glob.glob(f'./{i}_asmr3sec/**/*.wav', recursive=True)):\n","        x_melsp = calc_melsp(path)\n","        np.save(f\"./{i}_dataset/{number}\", x_melsp)\n","        number += 1"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4388,"status":"ok","timestamp":1710295784777,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"VPqLVqJE-8zY"},"outputs":[],"source":["# データセットクラスの定義\n","class ASMRDataset(Dataset):\n","    def __init__(self):\n","\n","        class_num = 2\n","        class_paths = {}\n","\n","        # クラスごとに対応するデータのパスを取得\n","        for i in range(class_num):\n","            data = glob.glob(f\".{str(i)}_dataset/*.npy\")\n","            class_paths[i] = data\n","\n","        id = 0\n","        self.id_class = {}\n","        self.id_path = {}\n","\n","        # クラスごとにデータIDを割り当てる\n","        for i in class_paths:\n","            for path in class_paths[i]:\n","                self.id_class[id] = i  # IDに対応するラベルを格納\n","                self.id_path[id] = path  # IDに対応するデータパスを格納\n","                id += 1\n","\n","    def __getitem__(self, idx):\n","        # 指定されたIDに対応するデータとラベルを取得し、Tensorに変換\n","        return torch.tensor(np.load(self.id_path[idx]).T).float(), self.id_class[idx]\n","\n","    def __len__(self):\n","        # データセットの総データ数を返す\n","        return len(self.id_class)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1472,"status":"ok","timestamp":1710295793159,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"R3XRsoAoXY6T"},"outputs":[],"source":["#訓練・検証データローダの作成\n","\n","dataset = ASMRDataset()\n","\n","length = len(dataset)\n","train_length = int(length*0.9)\n","val_length = length - train_length\n","\n","train,val = torch.utils.data.random_split(dataset,[train_length,val_length])\n","train_loader = DataLoader(train,batch_size=256,shuffle=True)\n","val_loader = DataLoader(val,batch_size=256,shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":530,"status":"ok","timestamp":1710296140894,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"Wlqt9QOOT03f","outputId":"76eede82-fac9-407e-e739-592d2d4345ed"},"outputs":[],"source":["## CNN自作モデル\n","\n","# CNNモデルの定義（VGGnet等を参考に）\n","class MyCNN(nn.Module):\n","    def __init__(self):\n","        super(MyCNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding='same')\n","        self.relu1 = nn.ReLU()\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n","        self.relu2 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=3)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n","        self.relu3 = nn.ReLU()\n","        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding='same')\n","        self.relu4 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=3)\n","        self.conv5 = nn.Conv2d(128, 256, kernel_size=5, padding='same')\n","        self.relu5 = nn.ReLU()\n","        self.pool3 = nn.MaxPool2d(kernel_size=5)\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(2560, 256)\n","        self.relu6 = nn.ReLU()\n","        self.fc2 = nn.Linear(256, 2)\n","\n","    def forward(self, x):\n","        x = self.relu1(self.conv1(x))\n","        x = self.relu2(self.conv2(x))\n","        x = self.pool1(x)\n","        x = self.relu3(self.conv3(x))\n","        x = self.relu4(self.conv4(x))\n","        x = self.pool2(x)\n","        x = self.relu5(self.conv5(x))\n","        x = self.pool3(x)\n","        x = self.flatten(x)\n","        x = self.relu6(self.fc1(x))\n","        x = self.fc2(x)\n","\n","        return x\n","\n","# モデルのインスタンス化\n","model = MyCNN()\n","\n","# 損失関数と最適化アルゴリズムの定義\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","#GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","summary(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3922174,"status":"ok","timestamp":1710300073024,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"zCUawzywUY0k","outputId":"385f95f4-bcab-4958-c014-d36d736e37d4"},"outputs":[],"source":["losses = []\n","for epoch in range(1, 21):\n","\n","    # 学習\n","    train_losses = 0\n","\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        x, y = data\n","        x = x.to(device, dtype=torch.float32)\n","        y = y.to(device)\n","        x = x.unsqueeze(1) # チャネル数1を挿入\n","        out = model(x)\n","        loss = criterion(out, y)\n","        loss.backward()\n","        optimizer.step()\n","        train_losses += loss.item()\n","\n","    # 検証\n","    val_losses = 0\n","    actual_list, predict_list = [], []\n","\n","    for data in val_loader:\n","        with torch.no_grad():\n","            x, y = data\n","            x = x.to(device, dtype=torch.float32)\n","            y = y.to(device)\n","            x = x.unsqueeze(1)\n","            out = model(x)\n","            loss = criterion(out, y)\n","            _, y_pred = torch.max(out, 1)\n","            val_losses += loss.item()\n","\n","            actual_list.append(y.cpu().numpy())\n","            predict_list.append(y_pred.cpu().numpy())\n","\n","    actual_list = np.concatenate(actual_list)\n","    predict_list = np.concatenate(predict_list)\n","    accuracy = np.mean(actual_list == predict_list)\n","\n","    # epoch毎の精度確認\n","    print(\"epoch\", epoch, \"\\t train_loss\", train_losses, \"\\t val_loss\", val_losses, \"\\t accuracy\", accuracy)\n","\n","    # 保存\n","    save_path = \"./cnn_model.pth\"\n","    torch.save({'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': train_losses,},\n","              save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7908,"status":"ok","timestamp":1710294077097,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"-hXEaz3cXvgO","outputId":"a0c038fc-e9d8-4b05-cc82-6d610050e65f"},"outputs":[],"source":["## 事前学習済みモデル（ResNet）\n","\n","#学習済みのResNetをダウンロード\n","resnet_model = resnet34(pretrained=True)\n","\n","\n","#最初の畳み込みのチャネル3をチャネル1に変更\n","resnet_model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","\n","#最後の層の次元をカテゴリ数に調整\n","resnet_model.fc = nn.Linear(512, 2)\n","\n","#GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","resnet_model = resnet_model.to(device)\n","\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(resnet_model.parameters(), lr=1e-4)\n","\n","#summary(resnet_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1418096,"status":"ok","timestamp":1710295497613,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"LmOE74fJeiiC","outputId":"46506009-a444-44a6-b01a-d402e01c818d"},"outputs":[],"source":["losses = []\n","for epoch in range(1, 21):\n","\n","    # 学習\n","    train_losses = 0\n","\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        x, y = data\n","        x = x.to(device, dtype=torch.float32)\n","        y = y.to(device)\n","        x = x.unsqueeze(1) # チャネル数1を挿入\n","        out = resnet_model(x)\n","        loss = loss_function(out, y)\n","        loss.backward()\n","        optimizer.step()\n","        train_losses += loss.item()\n","\n","    # 検証\n","    val_losses = 0\n","    actual_list, predict_list = [], []\n","\n","    for data in val_loader:\n","        with torch.no_grad():\n","            x, y = data\n","            x = x.to(device, dtype=torch.float32)\n","            y = y.to(device)\n","            x = x.unsqueeze(1)\n","            out = resnet_model(x)\n","            loss = loss_function(out, y)\n","            _, y_pred = torch.max(out, 1)\n","            val_losses += loss.item()\n","\n","            actual_list.append(y.cpu().numpy())\n","            predict_list.append(y_pred.cpu().numpy())\n","\n","    actual_list = np.concatenate(actual_list)\n","    predict_list = np.concatenate(predict_list)\n","    accuracy = np.mean(actual_list == predict_list)\n","\n","    # epoch毎の精度確認\n","    print(\"epoch\", epoch, \"\\t train_loss\", train_losses, \"\\t val_loss\", val_losses, \"\\t accuracy\", accuracy)\n","\n","    # 保存\n","    save_path = \"./resnet_model.pth\"\n","    torch.save({'epoch': epoch,\n","                'model_state_dict': resnet_model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': train_losses,},\n","              save_path)"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":369,"status":"ok","timestamp":1710307600442,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"4f3Sa0jw5ye8"},"outputs":[],"source":["#推論用データセットの作成\n","\n","class ASMRDataset2(Dataset):\n","    def __init__(self):\n","        i = 0\n","        class_paths = {}\n","        data = natsorted(glob.glob(\"./pred_dataset/*.npy\"))\n","        class_paths[i]=data\n","        id = 0\n","        self.id_class = {}\n","        self.id_path = {}\n","        for i in class_paths:\n","            for path in class_paths[i]:\n","                self.id_class[id]=i\n","                self.id_path[id]=path\n","                id+=1\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(np.load(self.id_path[idx]).T).float(), self.id_class[idx]\n","\n","    def __len__(self):\n","        return len(self.id_class)\n","\n","test = ASMRDataset2()\n","test_loader = DataLoader(test,batch_size=1,shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47526,"status":"ok","timestamp":1710307803028,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"7gF5UIGC51WX","outputId":"30441f6c-6b24-4454-822d-32ff88a6bb38"},"outputs":[],"source":["pred_y = []\n","\n","#推論(自作モデルの方が精度が良かったのでそちらを採用)\n","for batch in test_loader:\n","    with torch.no_grad():\n","        x, y = batch\n","        x = x.to(device, dtype=torch.float32)\n","        y = y.to(device)\n","        x = x.unsqueeze(1)\n","        out = model(x)\n","        _, y_pred = torch.max(out, 1)\n","        pred_y.append(y_pred.cpu().numpy())"]},{"cell_type":"code","execution_count":76,"metadata":{"executionInfo":{"elapsed":425,"status":"ok","timestamp":1710312499480,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"AR7YU8d6ImOr"},"outputs":[],"source":["#推論結果をデータフレームに\n","path = \"./pred_dataset/\"\n","\n","cut_title = []\n","asmr_number = []\n","track_number = []\n","\n","for path in natsorted(glob.glob('./pred_dataset/*.npy', recursive=True)):\n","  title = os.path.splitext(os.path.basename(path))[0]\n","  cut_title.append(title)\n","  asmr_number.append(int(title[:3])) #作品ナンバー\n","  track_number.append(int(title[4:7])) #作品内トラックナンバー\n","\n","pred_y = np.squeeze(pred_y)\n","pred_y = pred_y.tolist()\n","\n","pred_df = pd.DataFrame({'asmr_num':asmr_number, 'track_num':track_number, 'title':cut_title, 'pred':pred_y})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1710313987017,"user":{"displayName":"一二三伊織","userId":"15733888246253194873"},"user_tz":-540},"id":"WQA7e6ra94iH","outputId":"131e22d4-4b0a-4d98-ce79-ee3efbcc7d90"},"outputs":[],"source":["#結果を総合して分類\n","\n","asmr_num = asmr_number[-1]+1\n","asmr_preds = []\n","sum_track_pred = 0\n","sum_3s_pred = 0\n","all_title = []\n","\n","#asmr_preds:作品総評価リスト / sum_track_pred:trackごとの評価合計 / sum_3s_pred:3sごとの評価合計\n","\n","for j in range(asmr_num):\n","    \n","    #作品ナンバーごとのデータフレーム抽出\n","    temp_df1 = pred_df[pred_df['asmr_num'] == j] \n","    \n","    #音声形式の体験版がない作品は除外されているため、その分の作品ナンバーをスキップ\n","    if temp_df1.empty == True: \n","      continue\n","\n","    title = temp_df1.iloc[0, 2]\n","    title = title[12:]\n","    all_title.append(title)\n","\n","    #トラックごとに抽出\n","    sum_track_pred = 0\n","    track_num = temp_df1.iloc[-1]['track_num']+1\n","\n","    for k in range(1, track_num): \n","        sum_3s_pred = 0\n","        temp_df2 = temp_df1[temp_df1['track_num'] == k]\n","\n","        #トラック内で3sごとの評価\n","        for _3s_pred in temp_df2['pred']:\n","            if _3s_pred == 1:\n","                sum_3s_pred += 1\n","            elif _3s_pred == 0:\n","                sum_3s_pred += -1\n","\n","        #トラック評価\n","        if sum_3s_pred > 0:\n","            sum_track_pred += 1\n","        elif sum_3s_pred <= 0:\n","            sum_track_pred += 0\n","    \n","    #総合評価\n","    if sum_track_pred > 0:\n","      asmr_preds.append(1)\n","    elif sum_track_pred <= 0:\n","      asmr_preds.append(0)\n","\n","#最終推薦結果\n","pred_df_sum = pd.DataFrame({'title':all_title, 'asmr_preds':asmr_preds})\n","pred_df_sum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPYX9iKUrgJc"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyODPotYtIp53HFHc8FV+xUL","mount_file_id":"1ZwH9BDJQ6Lch0tlRyo334PtEIPXZ6VQH","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
